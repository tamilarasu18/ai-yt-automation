{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¤– AI YouTube Shorts â€” Google Colab Quickstart\n",
        "\n",
        "**Fully automated 11-step pipeline**: Topic â†’ Story â†’ SEO â†’ 5 Scene Images â†’ TTS â†’ SadTalker Avatar â†’ Subtitles â†’ Slideshow â†’ YouTube Upload\n",
        "\n",
        "ğŸ“¦ **Repository**: [github.com/tamilarasu18/ai-yt-automation](https://github.com/tamilarasu18/ai-yt-automation)\n",
        "\n",
        "---\n",
        "\n",
        "## â˜€ï¸ Daily Routine (After One-Time Setup)\n",
        "\n",
        "```\n",
        "1. Open this Colab notebook         â†’ 5 seconds (bookmark it!)\n",
        "2. Click \"Runtime â†’ Run all\"        â†’ 1 click\n",
        "3. Wait ~15 minutes                 â†’ go drink coffee â˜•\n",
        "4. Telegram notification pops       â†’ \"Video uploaded! âœ…\"\n",
        "5. Close Colab                      â†’ done for the day\n",
        "```\n",
        "\n",
        "> **1 click. 15 minutes. Video live on YouTube.**\n",
        "\n",
        "### âš¡ Smart Caching\n",
        "- **First run**: Downloads all models (~6 GB) â†’ caches to Drive\n",
        "- **Future runs**: Restores from Drive â†’ **saves ~10 min**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ Before You Start (One-Time Setup)\n",
        "\n",
        "1. **Runtime**: Go to **Runtime â†’ Change runtime type â†’ T4 GPU**\n",
        "2. **HuggingFace token** (free): Get from https://huggingface.co/settings/tokens\n",
        "3. **Google Drive** must have this structure:\n",
        "\n",
        "```\n",
        "MyDrive/\n",
        "â””â”€â”€ ai-youtube-automation/\n",
        "    â”œâ”€â”€ config.json              â† Your settings (includes HF token)\n",
        "    â”œâ”€â”€ client_secret.json       â† YouTube OAuth client\n",
        "    â”œâ”€â”€ service_account.json     â† Google Sheets auth\n",
        "    â””â”€â”€ videos/                  â† Output videos saved here\n",
        "```\n",
        "\n",
        "4. **Google Sheet** must be shared with your service account email"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ”§ Step 1 â€” Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 1: Mount Google Drive\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "DRIVE_BASE = '/content/drive/MyDrive/ai-youtube-automation'\n",
        "DRIVE_CACHE = f'{DRIVE_BASE}/models'\n",
        "\n",
        "# Verify credentials\n",
        "print('ğŸ“ Checking Google Drive...\\n')\n",
        "all_ok = True\n",
        "for name in ['config.json', 'service_account.json', 'client_secret.json']:\n",
        "    path = f'{DRIVE_BASE}/{name}'\n",
        "    exists = os.path.exists(path)\n",
        "    print(f'  {\"âœ…\" if exists else \"âŒ\"} {name}')\n",
        "    if not exists: all_ok = False\n",
        "\n",
        "cache_exists = os.path.exists(f'{DRIVE_CACHE}/ollama')\n",
        "print(f'\\n  {\"âœ…\" if cache_exists else \"â³\"} Model cache: {\"Found (fast restore!)\" if cache_exists else \"Not found (first run will download)\"}')\n",
        "\n",
        "if all_ok:\n",
        "    print('\\nâœ… Drive ready!')\n",
        "else:\n",
        "    print('\\nâš ï¸  Missing files! Upload them to Drive/ai-youtube-automation/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ“¦ Step 2 â€” Clone Repo & Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 2: Clone repo + Install packages (~3 min, always needed)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/ai-yt-automation'):\n",
        "    !git clone https://github.com/tamilarasu18/ai-yt-automation.git /content/ai-yt-automation\n",
        "else:\n",
        "    !cd /content/ai-yt-automation && git pull\n",
        "\n",
        "os.chdir('/content/ai-yt-automation')\n",
        "\n",
        "# System deps (zstd is required by Ollama installer)\n",
        "!apt-get update -qq && apt-get install -y -qq ffmpeg espeak-ng zstd > /dev/null 2>&1\n",
        "\n",
        "# Python deps (always reinstalled â€” Colab resets pip on disconnect)\n",
        "!pip install -e \".[dev,api,kokoro]\" -q 2>/dev/null\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q 2>/dev/null\n",
        "!pip install diffusers transformers accelerate safetensors -q 2>/dev/null\n",
        "!pip install moviepy==1.0.3 -q 2>/dev/null\n",
        "!pip install gspread google-auth google-auth-oauthlib google-api-python-client -q 2>/dev/null\n",
        "!pip install python-telegram-bot==20.7 openai-whisper -q 2>/dev/null\n",
        "\n",
        "print('\\nâœ… Packages installed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ¤– Step 3 â€” Setup Ollama + SadTalker (with Drive Cache)\n",
        "\n",
        "**First run**: Downloads models â†’ saves to Drive (~6 GB, ~10 min)\n",
        "\n",
        "**Future runs**: Restores from Drive (~1 min) âš¡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 3: Setup Ollama + SadTalker with Drive model caching\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import os, subprocess, time, shutil\n",
        "\n",
        "DRIVE_BASE = '/content/drive/MyDrive/ai-youtube-automation'\n",
        "DRIVE_CACHE = f'{DRIVE_BASE}/models'\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# OLLAMA SETUP\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "print('ğŸ¤– Setting up Ollama...')\n",
        "\n",
        "# Install Ollama (zstd must be installed first â€” done in Step 2)\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "# Restore Ollama models from Drive cache (if available)\n",
        "ollama_cache = f'{DRIVE_CACHE}/ollama'\n",
        "ollama_local = os.path.expanduser('~/.ollama/models')\n",
        "\n",
        "if os.path.exists(ollama_cache) and os.listdir(ollama_cache):\n",
        "    print('âš¡ Restoring Ollama model from Drive cache...')\n",
        "    os.makedirs(ollama_local, exist_ok=True)\n",
        "    !cp -r {ollama_cache}/* {ollama_local}/ 2>/dev/null\n",
        "    print('âœ… Ollama model restored from cache!')\n",
        "    need_pull = False\n",
        "else:\n",
        "    print('â³ No cache found â€” will download model')\n",
        "    need_pull = True\n",
        "\n",
        "# Start Ollama server (with retry if binary not found)\n",
        "try:\n",
        "    subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, start_new_session=True)\n",
        "except FileNotFoundError:\n",
        "    print('âš ï¸ Ollama binary not in PATH, trying /usr/local/bin/ollama...')\n",
        "    subprocess.Popen(['/usr/local/bin/ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, start_new_session=True)\n",
        "time.sleep(5)\n",
        "\n",
        "# Verify server is running\n",
        "import urllib.request\n",
        "server_ok = False\n",
        "for i in range(5):\n",
        "    try:\n",
        "        urllib.request.urlopen('http://localhost:11434/api/tags', timeout=3)\n",
        "        print('âœ… Ollama server running!')\n",
        "        server_ok = True\n",
        "        break\n",
        "    except Exception:\n",
        "        time.sleep(2)\n",
        "        print(f'   Retrying... ({(i+1)*2}s)')\n",
        "\n",
        "if not server_ok:\n",
        "    print('âŒ Ollama server failed to start. Try restarting the runtime.')\n",
        "\n",
        "# Pull model if not cached\n",
        "if need_pull and server_ok:\n",
        "    !ollama pull gemma3:4b\n",
        "    # Cache to Drive for next time\n",
        "    print('ğŸ’¾ Caching Ollama model to Drive...')\n",
        "    os.makedirs(ollama_cache, exist_ok=True)\n",
        "    !cp -r {ollama_local}/* {ollama_cache}/ 2>/dev/null\n",
        "    print('âœ… Ollama model cached to Drive!')\n",
        "elif server_ok:\n",
        "    !ollama list\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# SADTALKER SETUP\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "print('\\nğŸ—£ï¸ Setting up SadTalker...')\n",
        "\n",
        "sadtalker_cache = f'{DRIVE_CACHE}/sadtalker'\n",
        "sadtalker_local = '/content/SadTalker'\n",
        "\n",
        "if not os.path.exists(sadtalker_local):\n",
        "    !git clone -q https://github.com/OpenTalker/SadTalker.git {sadtalker_local}\n",
        "\n",
        "# Patch for numpy 2.0\n",
        "!sed -i 's/np.VisibleDeprecationWarning/DeprecationWarning/g' {sadtalker_local}/src/face3d/util/preprocess.py 2>/dev/null; true\n",
        "\n",
        "# Install SadTalker deps\n",
        "!pip install -q face-alignment==1.3.5 kornia==0.6.12 yacs facexlib gfpgan basicsr dlib 2>/dev/null\n",
        "!pip install -q -r {sadtalker_local}/requirements.txt 2>/dev/null; true\n",
        "\n",
        "# Restore or download SadTalker checkpoints\n",
        "checkpoints_dir = f'{sadtalker_local}/checkpoints'\n",
        "if os.path.exists(sadtalker_cache) and os.listdir(sadtalker_cache):\n",
        "    print('âš¡ Restoring SadTalker models from Drive cache...')\n",
        "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "    !cp -r {sadtalker_cache}/* {checkpoints_dir}/ 2>/dev/null\n",
        "    gfpgan_cache = f'{DRIVE_CACHE}/gfpgan'\n",
        "    if os.path.exists(gfpgan_cache):\n",
        "        !cp -r {gfpgan_cache}/* {sadtalker_local}/gfpgan/ 2>/dev/null; true\n",
        "    print('âœ… SadTalker models restored from cache!')\n",
        "else:\n",
        "    print('â³ Downloading SadTalker models...')\n",
        "    !cd {sadtalker_local} && bash scripts/download_models.sh 2>/dev/null; true\n",
        "    print('ğŸ’¾ Caching SadTalker models to Drive...')\n",
        "    os.makedirs(sadtalker_cache, exist_ok=True)\n",
        "    !cp -r {checkpoints_dir}/* {sadtalker_cache}/ 2>/dev/null\n",
        "    gfpgan_cache = f'{DRIVE_CACHE}/gfpgan'\n",
        "    gfpgan_local = f'{sadtalker_local}/gfpgan'\n",
        "    if os.path.exists(gfpgan_local):\n",
        "        os.makedirs(gfpgan_cache, exist_ok=True)\n",
        "        !cp -r {gfpgan_local}/* {gfpgan_cache}/ 2>/dev/null; true\n",
        "    print('âœ… SadTalker models cached to Drive!')\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STABLE DIFFUSION CACHE (HuggingFace)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "print('\\nğŸ–¼ï¸ Setting up Stable Diffusion cache...')\n",
        "\n",
        "hf_cache_drive = f'{DRIVE_CACHE}/huggingface'\n",
        "hf_cache_local = os.path.expanduser('~/.cache/huggingface')\n",
        "\n",
        "if os.path.exists(hf_cache_drive) and os.listdir(hf_cache_drive):\n",
        "    print('âš¡ Restoring HuggingFace models from Drive cache...')\n",
        "    os.makedirs(hf_cache_local, exist_ok=True)\n",
        "    !cp -r {hf_cache_drive}/* {hf_cache_local}/ 2>/dev/null\n",
        "    print('âœ… SD model restored from cache!')\n",
        "else:\n",
        "    print('â³ SD model will download on first pipeline run')\n",
        "    print('   (will be cached to Drive automatically after)')\n",
        "\n",
        "os.chdir('/content/ai-yt-automation')\n",
        "print('\\n' + '='*50)\n",
        "print('âœ… All models ready!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## âš™ï¸ Step 4 â€” Load Config & Set Environment\n",
        "\n",
        "> âš ï¸ **HuggingFace Token Required**: Stable Diffusion models now require authentication.\n",
        "> Get a free token at https://huggingface.co/settings/tokens and add `\"hf_token\"` to your `config.json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 4: Load config from Drive + set environment variables\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import json, os, shutil\n",
        "\n",
        "DRIVE_BASE = '/content/drive/MyDrive/ai-youtube-automation'\n",
        "WORK_DIR = '/content/ai-yt-automation'\n",
        "\n",
        "# Copy credential files from Drive\n",
        "for fname in ['service_account.json', 'client_secret.json']:\n",
        "    src = f'{DRIVE_BASE}/{fname}'\n",
        "    dst = f'{WORK_DIR}/{fname}'\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "        print(f'  âœ… {fname}')\n",
        "    else:\n",
        "        print(f'  âš ï¸  {fname} not found')\n",
        "\n",
        "# Load config.json\n",
        "config = {}\n",
        "config_path = f'{DRIVE_BASE}/config.json'\n",
        "if os.path.exists(config_path):\n",
        "    with open(config_path) as f:\n",
        "        config = json.load(f)\n",
        "    print(f'  âœ… config.json loaded')\n",
        "\n",
        "# Map config keys â†’ env vars\n",
        "env_map = {\n",
        "    'google_sheet_url': 'GOOGLE_SHEET_URL',\n",
        "    'google_sheet_name': 'GOOGLE_SHEET_NAME',\n",
        "    'youtube_client_id': 'YOUTUBE_CLIENT_ID',\n",
        "    'youtube_client_secret': 'YOUTUBE_CLIENT_SECRET',\n",
        "    'youtube_refresh_token': 'YOUTUBE_REFRESH_TOKEN',\n",
        "    'telegram_bot_token': 'TELEGRAM_BOT_TOKEN',\n",
        "    'telegram_chat_id': 'TELEGRAM_CHAT_ID',\n",
        "    'video_privacy': 'VIDEO_PRIVACY',\n",
        "    'auto_upload_youtube': 'AUTO_UPLOAD_YOUTUBE',\n",
        "}\n",
        "for k, v in env_map.items():\n",
        "    val = config.get(k, '')\n",
        "    if val: os.environ[v] = str(val)\n",
        "\n",
        "# â”€â”€ HuggingFace Authentication â”€â”€\n",
        "# Required for Stable Diffusion model download\n",
        "hf_token = config.get('hf_token', '')\n",
        "if hf_token:\n",
        "    os.environ['HF_TOKEN'] = hf_token\n",
        "    os.environ['HUGGING_FACE_HUB_TOKEN'] = hf_token\n",
        "    print(f'  âœ… HuggingFace token set')\n",
        "else:\n",
        "    print('  âš ï¸  No hf_token in config.json â€” SD model download may fail!')\n",
        "    print('     Get a free token at: https://huggingface.co/settings/tokens')\n",
        "    print('     Add to config.json: \"hf_token\": \"hf_xxxxxxxxxxxx\"')\n",
        "\n",
        "# Fixed Colab paths\n",
        "os.environ['GOOGLE_SERVICE_ACCOUNT_FILE'] = f'{WORK_DIR}/service_account.json'\n",
        "os.environ['WORK_DIR'] = WORK_DIR\n",
        "os.environ['OUTPUT_DIR'] = f'{WORK_DIR}/output'\n",
        "os.environ['AVATAR_IMAGE_PATH'] = f'{WORK_DIR}/assets/images/avatar.png'\n",
        "os.environ['SADTALKER_DIR'] = '/content/SadTalker'\n",
        "os.environ['DRIVE_OUTPUT_FOLDER'] = config.get('drive_output_folder', f'{DRIVE_BASE}/videos')\n",
        "\n",
        "# Engine config (optimized for T4)\n",
        "os.environ['OLLAMA_HOST'] = 'http://localhost:11434'\n",
        "os.environ['OLLAMA_MODEL'] = 'gemma3:4b'\n",
        "os.environ['TTS_ENGINE'] = 'edge'\n",
        "os.environ['IMAGE_ENGINE'] = 'sd'\n",
        "os.environ['SD_MODEL'] = 'stabilityai/stable-diffusion-2-1'\n",
        "os.environ['ENABLE_FACE_ENHANCEMENT'] = 'true'\n",
        "os.environ['WHISPER_MODEL_SIZE'] = 'base'\n",
        "os.environ['SDXL_INFERENCE_STEPS'] = '20'\n",
        "\n",
        "# Check avatar exists (should be in the cloned repo)\n",
        "avatar_path = os.environ['AVATAR_IMAGE_PATH']\n",
        "if not os.path.exists(avatar_path):\n",
        "    # Fallback: try to copy from Drive\n",
        "    for ext in ['png', 'webp', 'jpg']:\n",
        "        drive_avatar = f'{DRIVE_BASE}/avatar.{ext}'\n",
        "        if os.path.exists(drive_avatar):\n",
        "            os.makedirs(os.path.dirname(avatar_path), exist_ok=True)\n",
        "            shutil.copy(drive_avatar, avatar_path)\n",
        "            print(f'  âœ… Avatar copied from Drive ({ext})')\n",
        "            break\n",
        "    else:\n",
        "        print('  âš ï¸  Avatar not found! Upload avatar.png to Drive/ai-youtube-automation/')\n",
        "else:\n",
        "    print(f'  âœ… Avatar found in repo')\n",
        "\n",
        "os.makedirs(os.environ['OUTPUT_DIR'], exist_ok=True)\n",
        "os.makedirs(os.environ['DRIVE_OUTPUT_FOLDER'], exist_ok=True)\n",
        "\n",
        "print(f'\\nğŸ“‹ Config: TTS={os.environ[\"TTS_ENGINE\"]} | Images={os.environ[\"SD_MODEL\"].split(\"/\")[-1]} | LLM={os.environ[\"OLLAMA_MODEL\"]}')\n",
        "print(f'   HF Auth: {\"âœ…\" if hf_token else \"âŒ Missing\"}')\n",
        "print('âœ… Environment ready!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## âœ… Step 5 â€” Verify Everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 5: System check\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import os, subprocess\n",
        "os.chdir('/content/ai-yt-automation')\n",
        "\n",
        "print('ğŸ” System Check\\n')\n",
        "checks = []\n",
        "\n",
        "# GPU\n",
        "import torch\n",
        "gpu = torch.cuda.is_available()\n",
        "checks.append(('GPU', gpu, torch.cuda.get_device_name(0) if gpu else 'No GPU'))\n",
        "\n",
        "# Ollama\n",
        "try:\n",
        "    r = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=5)\n",
        "    checks.append(('Ollama', r.returncode == 0, 'Running'))\n",
        "except: checks.append(('Ollama', False, 'Not running'))\n",
        "\n",
        "# FFmpeg\n",
        "try:\n",
        "    r = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True, timeout=5)\n",
        "    checks.append(('FFmpeg', r.returncode == 0, 'Installed'))\n",
        "except: checks.append(('FFmpeg', False, 'Missing'))\n",
        "\n",
        "# Files\n",
        "for name, path in [\n",
        "    ('Avatar', os.environ.get('AVATAR_IMAGE_PATH', '')),\n",
        "    ('Credentials', os.environ.get('GOOGLE_SERVICE_ACCOUNT_FILE', '')),\n",
        "    ('SadTalker', '/content/SadTalker/checkpoints'),\n",
        "]:\n",
        "    checks.append((name, os.path.exists(path), path.split('/')[-1]))\n",
        "\n",
        "# HuggingFace token\n",
        "hf_ok = bool(os.environ.get('HF_TOKEN', ''))\n",
        "checks.append(('HF Token', hf_ok, 'Set' if hf_ok else 'Missing â€” add hf_token to config.json'))\n",
        "\n",
        "# Python packages\n",
        "for pkg_name, imp in [('Edge TTS','edge_tts'),('Diffusers','diffusers'),('Whisper','whisper'),('MoviePy','moviepy')]:\n",
        "    try: __import__(imp); checks.append((pkg_name, True, 'âœ“'))\n",
        "    except: checks.append((pkg_name, False, 'Missing'))\n",
        "\n",
        "# Drive cache\n",
        "DRIVE_BASE = '/content/drive/MyDrive/ai-youtube-automation'\n",
        "cache = os.path.exists(f'{DRIVE_BASE}/models/ollama')\n",
        "checks.append(('Model Cache', cache, 'Cached on Drive' if cache else 'Will cache after first run'))\n",
        "\n",
        "for name, ok, detail in checks:\n",
        "    print(f'  {\"âœ…\" if ok else \"âŒ\"} {name:16s} {detail}')\n",
        "\n",
        "failed = sum(1 for _, ok, _ in checks if not ok)\n",
        "print(f'\\n{\"ğŸš€ Ready!\" if failed == 0 else f\"âš ï¸ {failed} issue(s) â€” fix above\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ§ª Step 6 â€” Test Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 6: Test pipeline (story â†’ 5 images â†’ audio)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import os\n",
        "os.chdir('/content/ai-yt-automation')\n",
        "!python -m ai_shorts run --mode test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ¬ Step 7 â€” Full Pipeline\n",
        "\n",
        "```\n",
        " 1. Fetch topic        â†’ Google Sheet\n",
        " 2. Generate story     â†’ Ollama (randomized styles)\n",
        " 3. Generate SEO       â†’ title, description, hashtags\n",
        " 4. Generate 5 prompts â†’ one per scene\n",
        " 5. Generate 5 images  â†’ Stable Diffusion (T4 GPU)\n",
        " 6. Generate audio     â†’ Edge TTS\n",
        " 7. Animate avatar     â†’ SadTalker (talking head)\n",
        " 8. Generate subtitles â†’ Whisper\n",
        " 9. Compose slideshow  â†’ MoviePy (5 images + avatar overlay)\n",
        "10. Upload YouTube     â†’ resumable + scheduler\n",
        "11. Backup + Notify    â†’ Google Drive + Telegram\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 7: Full pipeline ğŸš€\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import os\n",
        "os.chdir('/content/ai-yt-automation')\n",
        "!python -m ai_shorts run --mode full"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ’¾ Step 8 â€” Cache SD Model to Drive (run after first pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 8: Cache HuggingFace SD model to Drive (run ONCE)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import os\n",
        "\n",
        "DRIVE_CACHE = '/content/drive/MyDrive/ai-youtube-automation/models'\n",
        "hf_local = os.path.expanduser('~/.cache/huggingface')\n",
        "hf_drive = f'{DRIVE_CACHE}/huggingface'\n",
        "\n",
        "if os.path.exists(hf_local) and not os.path.exists(hf_drive):\n",
        "    print('ğŸ’¾ Caching HuggingFace SD model to Drive...')\n",
        "    print('   This may take 2-3 minutes (one-time only)')\n",
        "    os.makedirs(hf_drive, exist_ok=True)\n",
        "    !cp -r {hf_local}/* {hf_drive}/ 2>/dev/null\n",
        "    print('âœ… SD model cached to Drive!')\n",
        "elif os.path.exists(hf_drive):\n",
        "    print('âœ… SD model already cached on Drive')\n",
        "else:\n",
        "    print('âš ï¸  Run the pipeline first to download the SD model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ“º Step 9 â€” Preview & Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 9: Preview + download\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "from IPython.display import Video, display, Image\n",
        "from pathlib import Path\n",
        "import glob, shutil, os\n",
        "\n",
        "output_dir = Path('/content/ai-yt-automation/output')\n",
        "DRIVE_BASE = '/content/drive/MyDrive/ai-youtube-automation'\n",
        "\n",
        "# Show scene images\n",
        "scenes = sorted(glob.glob(str(output_dir / '*/scenes/scene_*.png')))\n",
        "if scenes:\n",
        "    print(f'ğŸ–¼ï¸  {len(scenes)} Scene Images:\\n')\n",
        "    for img in scenes:\n",
        "        display(Image(filename=img, width=250))\n",
        "\n",
        "# Show video\n",
        "videos = sorted(glob.glob(str(output_dir / '*/final_video.mp4')))\n",
        "if videos:\n",
        "    print(f'\\nğŸ¬ Final Video:')\n",
        "    display(Video(videos[-1], width=360))\n",
        "    drive_out = os.environ.get('DRIVE_OUTPUT_FOLDER', f'{DRIVE_BASE}/videos')\n",
        "    os.makedirs(drive_out, exist_ok=True)\n",
        "    shutil.copy(videos[-1], f'{drive_out}/latest_video.mp4')\n",
        "    print(f'ğŸ’¾ Saved to: {drive_out}/latest_video.mp4')\n",
        "else:\n",
        "    print('âš ï¸  No video found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download to your computer\n",
        "from google.colab import files\n",
        "import glob\n",
        "videos = sorted(glob.glob('/content/ai-yt-automation/output/*/final_video.mp4'))\n",
        "if videos: files.download(videos[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ”‘ One-Time: YouTube OAuth Token\n",
        "\n",
        "Run only ONCE to generate your YouTube refresh token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ONE-TIME: Generate YouTube refresh token\n",
        "!pip install google-auth-oauthlib google-api-python-client -q\n",
        "\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "import os\n",
        "\n",
        "DRIVE_BASE = '/content/drive/MyDrive/ai-youtube-automation'\n",
        "secret = '/content/ai-yt-automation/client_secret.json'\n",
        "if not os.path.exists(secret):\n",
        "    secret = f'{DRIVE_BASE}/client_secret.json'\n",
        "\n",
        "flow = InstalledAppFlow.from_client_secrets_file(\n",
        "    secret, ['https://www.googleapis.com/auth/youtube.upload']\n",
        ")\n",
        "creds = flow.run_local_server(port=0)\n",
        "\n",
        "print('=' * 50)\n",
        "print('ğŸ”‘ Add these to config.json in Drive:')\n",
        "print('=' * 50)\n",
        "print(f'\"youtube_client_id\": \"{creds.client_id}\",')\n",
        "print(f'\"youtube_client_secret\": \"{creds.client_secret}\",')\n",
        "print(f'\"youtube_refresh_token\": \"{creds.refresh_token}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ğŸ“ config.json Template\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"hf_token\": \"hf_xxxxxxxxxxxxxxxxxxxx\",\n",
        "  \"google_sheet_url\": \"https://docs.google.com/spreadsheets/d/YOUR_SHEET_ID/edit\",\n",
        "  \"google_sheet_name\": \"Sheet1\",\n",
        "  \"youtube_client_id\": \"YOUR_CLIENT_ID.apps.googleusercontent.com\",\n",
        "  \"youtube_client_secret\": \"GOCSPX-your-secret\",\n",
        "  \"youtube_refresh_token\": \"1//your-refresh-token\",\n",
        "  \"telegram_bot_token\": \"1234567890:AAxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n",
        "  \"telegram_chat_id\": \"123456789\",\n",
        "  \"auto_upload_youtube\": true,\n",
        "  \"video_privacy\": \"public\",\n",
        "  \"drive_output_folder\": \"/content/drive/MyDrive/ai-youtube-automation/videos\"\n",
        "}\n",
        "```\n",
        "\n",
        "> âš ï¸ **Get your HuggingFace token** (free): https://huggingface.co/settings/tokens\n",
        "\n",
        "## ğŸ› ï¸ Troubleshooting\n",
        "\n",
        "| Issue | Fix |\n",
        "|-------|-----|\n",
        "| `CUDA out of memory` | Runtime â†’ Restart runtime â†’ Run all |\n",
        "| `401 Unauthorized` (SD model) | Add `hf_token` to config.json |\n",
        "| `Ollama connection refused` | Re-run Step 3 |\n",
        "| `Avatar not found` | Upload avatar.png to Drive or re-clone repo |\n",
        "| `SadTalker model not found` | Re-run Step 3 |\n",
        "| `Edge TTS timeout` | Change to `kokoro` in Step 4 |\n",
        "| `No topics found` | Add rows with Status=`Pending` in Sheet |\n",
        "| `YouTube token expired` | Re-run OAuth cell above |\n",
        "\n",
        "### ğŸ“ Drive Structure After First Run\n",
        "```\n",
        "MyDrive/ai-youtube-automation/\n",
        "â”œâ”€â”€ config.json                â† Must include hf_token!\n",
        "â”œâ”€â”€ service_account.json\n",
        "â”œâ”€â”€ client_secret.json\n",
        "â”œâ”€â”€ models/                    â† Auto-cached (~6 GB)\n",
        "â”‚   â”œâ”€â”€ ollama/                â† Gemma 3 4B\n",
        "â”‚   â”œâ”€â”€ sadtalker/             â† SadTalker checkpoints\n",
        "â”‚   â”œâ”€â”€ gfpgan/                â† Face enhancement\n",
        "â”‚   â””â”€â”€ huggingface/           â† Stable Diffusion 2.1\n",
        "â””â”€â”€ videos/                    â† Output videos\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**Built with Clean Architecture â¤ï¸ â€” Your AI Employee Working 24/7**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
