<div align="center">

# ğŸ¤– AI YouTube Shorts â€” Automated Video Pipeline

**Production-grade AI pipeline built with Clean Architecture that auto-generates and publishes motivational YouTube Shorts.**

_Story Generation â†’ Voice Synthesis â†’ Talking Avatar â†’ Video Composition â†’ Auto Upload_

[![CI](https://github.com/tamilarasu/ai-youtube-automation/actions/workflows/ci.yml/badge.svg)](https://github.com/tamilarasu/ai-youtube-automation/actions)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-3776AB.svg?logo=python&logoColor=white)](https://www.python.org)
[![Architecture](https://img.shields.io/badge/architecture-Clean%20%2F%20Hexagonal-blueviolet)](docs/architecture.md)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)
[![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)](pyproject.toml)

</div>

---

## ğŸ¬ Pipeline Flowchart

```mermaid
flowchart TD
    A["ğŸ“‹ Google Sheet<br/>(Topic Queue)"] --> B["1ï¸âƒ£ Fetch Topic"]
    B --> C["2ï¸âƒ£ Generate Story<br/>(Ollama LLM)"]
    C --> D{"Randomized<br/>320 Combos"}
    D --> E["3ï¸âƒ£ Generate SEO<br/>(Title + Tags + Hashtags)"]
    E --> F["4ï¸âƒ£ Generate 5 Prompts<br/>(Ollama â†’ scene descriptions)"]
    F --> G["5ï¸âƒ£ Generate 5 Images<br/>(Stable Diffusion)"]
    G --> H["6ï¸âƒ£ Generate Audio<br/>(Edge TTS / Kokoro)"]
    H --> I["7ï¸âƒ£ Animate Avatar<br/>(SadTalker)"]
    I --> J["8ï¸âƒ£ Generate Subtitles<br/>(Whisper STT)"]
    J --> K["9ï¸âƒ£ Compose Slideshow<br/>(MoviePy)"]
    K --> L{"Features"}

    L --> L1["ğŸµ Background Music<br/>(looped @ 1% vol)"]
    L --> L2["ğŸ“ Styled Subtitles<br/>(TextClip rendering)"]
    L --> L3["ğŸ–¼ï¸ 5 Images + Avatar<br/>(crossfade + overlay)"]

    L1 --> M["ğŸ”Ÿ Upload YouTube<br/>(resumable + scheduler)"]
    L2 --> M
    L3 --> M

    M --> N["1ï¸âƒ£1ï¸âƒ£ Backup + Notify"]
    N --> O["ğŸ’¾ Google Drive"]
    N --> P["ğŸ“± Telegram"]

    style A fill:#4285F4,color:white
    style C fill:#EA4335,color:white
    style G fill:#9C27B0,color:white
    style H fill:#34A853,color:white
    style I fill:#FBBC05,color:white
    style K fill:#FF7043,color:white
    style M fill:#FF0000,color:white
```

---

## ğŸ§  System Architecture

```mermaid
graph TB
    subgraph PRESENTATION["ğŸ–¥ï¸ Presentation Layer"]
        CLI["CLI<br/>(argparse + Rich)"]
        API["FastAPI<br/>REST API"]
    end

    subgraph APPLICATION["âš™ï¸ Application Layer"]
        Pipeline["Pipeline<br/>Orchestrator"]
        UC1["GenerateStory<br/>UseCase"]
        UC2["GenerateVoice<br/>UseCase"]
        UC3["CreateAvatar<br/>UseCase"]
        UC4["PublishVideo<br/>UseCase"]
    end

    subgraph DOMAIN["ğŸ›ï¸ Domain Layer (Core)"]
        Entities["Entities<br/>Topic, Story, Voice,<br/>VideoAsset, SceneSegment"]
        Ports["Ports (Interfaces)<br/>StoryGenerator, VoiceGenerator,<br/>BackgroundGenerator, etc."]
        VO["Value Objects<br/>Language, VideoMode,<br/>AssetType, VideoPrivacy"]
        Exceptions["Typed Exceptions<br/>PipelineError hierarchy"]
    end

    subgraph INFRASTRUCTURE["ğŸ”§ Infrastructure Layer"]
        Ollama["Ollama<br/>Adapter"]
        EdgeTTS["Edge TTS<br/>Adapter"]
        Kokoro["Kokoro TTS<br/>Adapter"]
        SadTalker["SadTalker<br/>Adapter"]
        SDXL["SDXL<br/>Adapter"]
        SD["Stable Diffusion<br/>Adapter"]
        MoviePy["MoviePy<br/>Composer"]
        YouTube["YouTube<br/>Uploader"]
        Sheets["Google Sheets<br/>Repository"]
        Drive["Google Drive<br/>Storage"]
        Whisper["Whisper<br/>Subtitles"]
        Telegram["Telegram<br/>Notifier"]
    end

    subgraph CORE["ğŸ§± Core (Cross-cutting)"]
        Config["Settings<br/>(Pydantic)"]
        DI["Container<br/>(DI)"]
        Resilience["Retry<br/>Decorator"]
        GPU["GPU<br/>Manager"]
    end

    CLI --> Pipeline
    API --> Pipeline
    Pipeline --> UC1 & UC2 & UC3 & UC4
    UC1 & UC2 & UC3 & UC4 --> Ports
    Ports -.->|implements| Ollama & EdgeTTS & Kokoro & SadTalker & SDXL & SD & MoviePy & YouTube & Sheets & Drive & Whisper & Telegram
    DI -.->|resolves| Ollama & EdgeTTS & Kokoro & SadTalker & SDXL & SD & MoviePy & YouTube

    style DOMAIN fill:#E8F5E9,stroke:#4CAF50,stroke-width:2px
    style APPLICATION fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style INFRASTRUCTURE fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style PRESENTATION fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style CORE fill:#ECEFF1,stroke:#607D8B,stroke-width:2px
```

---

## ğŸ”Œ Config-Driven Adapter Selection

Swap adapters at runtime via `.env` â€” zero code changes:

```mermaid
flowchart LR
    subgraph ENV[".env Configuration"]
        E1["TTS_ENGINE=edge"]
        E2["IMAGE_ENGINE=sdxl"]
    end

    subgraph CONTAINER["DI Container"]
        C1{"tts_engine?"}
        C2{"image_engine?"}
    end

    subgraph ADAPTERS["Adapters"]
        A1["EdgeTTSVoiceGenerator"]
        A2["KokoroVoiceGenerator"]
        A3["SDXLBackgroundGenerator"]
        A4["StableDiffusionBackgroundGenerator"]
    end

    E1 --> C1
    E2 --> C2
    C1 -->|"edge"| A1
    C1 -->|"kokoro"| A2
    C2 -->|"sdxl"| A3
    C2 -->|"sd"| A4

    style A1 fill:#34A853,color:white
    style A2 fill:#4285F4,color:white
    style A3 fill:#EA4335,color:white
    style A4 fill:#FBBC05,color:white
```

---

## ğŸ“Š Domain Model

```mermaid
classDiagram
    class Topic {
        +str text
        +Language language
        +TopicStatus status
        +mark_processing()
        +mark_done()
        +mark_failed()
    }

    class Story {
        +str text
        +Language language
        +int word_count
        +validate(min, max)
    }

    class Voice {
        +Path audio_path
        +float duration_seconds
        +Language language
        +str voice_id
    }

    class VideoAsset {
        +Path path
        +AssetType asset_type
        +float duration_seconds
        +bool exists
    }

    class SceneSegment {
        +float start
        +float end
        +int image_number
        +str prompt
        +float duration
    }

    class VideoOutput {
        +Path local_path
        +str youtube_url
        +str drive_path
        +VideoMetadata metadata
        +str scheduled_time
        +VideoMode video_mode
    }

    class PipelineResult {
        +Topic topic
        +Story story
        +Voice voice
        +list~VideoOutput~ outputs
        +bool success
        +str error
    }

    Topic --> Story : generates
    Story --> Voice : synthesizes
    Voice --> VideoAsset : produces
    VideoAsset --> VideoOutput : composes
    PipelineResult --> Topic
    PipelineResult --> VideoOutput
```

---

## ğŸš¨ Error Handling Strategy

```mermaid
flowchart TD
    PE["PipelineError (base)"] --> CE["ConfigurationError"]
    PE --> TFE["TopicFetchError"]
    PE --> SGE["StoryGenerationError"]
    PE --> VGE["VoiceGenerationError"]
    PE --> AAE["AvatarAnimationError"]
    PE --> SE["SubtitleError"]
    PE --> BGE["BackgroundGenerationError"]
    PE --> VCE["VideoCompositionError"]
    PE --> UE["UploadError"]
    PE --> NE["NotificationError âš¡"]

    NE -.->|"non-fatal"| CONT["Pipeline continues"]
    CE & TFE & SGE & VGE & AAE & BGE & VCE & UE -->|"fatal"| FAIL["Pipeline halts"]
    SE -.->|"graceful"| CONT

    style PE fill:#F44336,color:white
    style NE fill:#FF9800,color:white
    style SE fill:#FF9800,color:white
    style CONT fill:#4CAF50,color:white
    style FAIL fill:#B71C1C,color:white
```

---

## âš¡ Tech Stack

| Layer         | Technology                  | Purpose                                        |
| ------------- | --------------------------- | ---------------------------------------------- |
| **LLM**       | Ollama (Gemma 3 12B)        | Story generation, SEO metadata, image prompts  |
| **TTS**       | Edge TTS / Kokoro           | Voice synthesis (cloud or local, configurable) |
| **Avatar**    | SadTalker + GFPGAN          | Talking-head video generation                  |
| **STT**       | OpenAI Whisper              | Subtitle generation from audio                 |
| **Image Gen** | SDXL / Stable Diffusion 2.1 | 5 scene images per video (local GPU)           |
| **Video**     | MoviePy + FFmpeg            | Slideshow + avatar overlay + bgm + subtitles   |
| **Queue**     | Google Sheets API           | Topic management                               |
| **Upload**    | YouTube Data API v3         | Resumable upload with scheduling               |
| **Notify**    | Telegram Bot API            | Pipeline notifications                         |
| **Storage**   | Google Drive API            | Video backup                                   |
| **Config**    | Pydantic Settings           | Type-safe .env loading                         |
| **API**       | FastAPI + Uvicorn           | REST API for remote triggering                 |
| **DI**        | Custom Container            | Config-driven adapter selection                |
| **CI/CD**     | GitHub Actions              | Lint (Ruff) + Tests (Pytest)                   |

> **Total cost: $0** â€” All components are free-tier or open-source. No external API keys required.

---

## ğŸ—ï¸ Clean Architecture Principles

| Principle                  | Implementation                                  |
| -------------------------- | ----------------------------------------------- |
| **Dependency Inversion**   | Domain ports (ABC) â†’ Infrastructure adapters    |
| **Single Responsibility**  | One use case per operation                      |
| **Open/Closed**            | New adapters without modifying business logic   |
| **Interface Segregation**  | 13 focused port interfaces                      |
| **Separation of Concerns** | 5 distinct layers with clear boundaries         |
| **Dependency Injection**   | Container wires ports â†’ adapters at startup     |
| **Fail-Safe Design**       | Typed exceptions, retry with backoff, fallbacks |
| **GPU Lifecycle**          | Context managers for VRAM management            |

---

## ğŸ“ Project Structure

```
ai-youtube-automation-clean/
â”œâ”€â”€ src/ai_shorts/
â”‚   â”œâ”€â”€ domain/                    # ğŸ›ï¸ Business core (zero dependencies)
â”‚   â”‚   â”œâ”€â”€ entities.py            # Topic, Story, Voice, VideoAsset, SceneSegment, VideoOutput
â”‚   â”‚   â”œâ”€â”€ value_objects.py       # Language, VideoMode, AssetType, VideoPrivacy
â”‚   â”‚   â”œâ”€â”€ ports.py               # 13 abstract interfaces (contracts)
â”‚   â”‚   â””â”€â”€ exceptions.py          # 9 typed exceptions (one per pipeline stage)
â”‚   â”‚
â”‚   â”œâ”€â”€ application/               # âš™ï¸ Use cases + orchestrator
â”‚   â”‚   â”œâ”€â”€ use_cases.py           # 7 use cases (GenerateStory, GenerateSceneImages, etc.)
â”‚   â”‚   â””â”€â”€ pipeline.py            # PipelineOrchestrator (11-step sequencing)
â”‚   â”‚
â”‚   â”œâ”€â”€ infrastructure/adapters/   # ğŸ”§ External service implementations
â”‚   â”‚   â”œâ”€â”€ ollama.py              # LLM (story + metadata + 5 scene prompts)
â”‚   â”‚   â”œâ”€â”€ edge_tts.py            # Cloud TTS (Microsoft Edge)
â”‚   â”‚   â”œâ”€â”€ kokoro_tts.py          # Local TTS (CPU-friendly)
â”‚   â”‚   â”œâ”€â”€ sadtalker.py           # Avatar animation (talking head)
â”‚   â”‚   â”œâ”€â”€ whisper.py             # Speech-to-text subtitles
â”‚   â”‚   â”œâ”€â”€ sdxl.py                # SDXL image gen (local GPU)
â”‚   â”‚   â”œâ”€â”€ flux_image.py          # SD 2.1 + SceneImageGenerator (local GPU)
â”‚   â”‚   â”œâ”€â”€ moviepy_composer.py    # Slideshow + avatar overlay + bgm + subtitles
â”‚   â”‚   â”œâ”€â”€ youtube.py             # YouTube upload + scheduling
â”‚   â”‚   â”œâ”€â”€ google_sheets.py       # Topic queue (Google Sheets)
â”‚   â”‚   â”œâ”€â”€ google_drive.py        # Cloud backup
â”‚   â”‚   â””â”€â”€ telegram.py            # Notifications
â”‚   â”‚
â”‚   â”œâ”€â”€ presentation/              # ğŸ–¥ï¸ User interfaces
â”‚   â”‚   â””â”€â”€ api.py                 # FastAPI REST API (/generate, /batch, /health)
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                      # ğŸ§± Cross-cutting concerns
â”‚   â”‚   â”œâ”€â”€ config.py              # Pydantic Settings (type-safe .env)
â”‚   â”‚   â”œâ”€â”€ container.py           # DI Container (config-driven adapter wiring)
â”‚   â”‚   â”œâ”€â”€ resilience.py          # retry_with_backoff decorator
â”‚   â”‚   â”œâ”€â”€ gpu.py                 # GPU memory management
â”‚   â”‚   â”œâ”€â”€ timer.py               # Pipeline timing instrumentation
â”‚   â”‚   â””â”€â”€ logging.py             # Structured logging setup
â”‚   â”‚
â”‚   â””â”€â”€ cli.py                     # CLI (run, setup, serve, batch)
â”‚
â”œâ”€â”€ assets/images/avatar.png       # Default avatar image
â”œâ”€â”€ tests/                         # 31 unit tests
â”œâ”€â”€ docs/                          # Architecture docs + setup guide
â”œâ”€â”€ .github/workflows/ci.yml       # GitHub Actions CI
â””â”€â”€ pyproject.toml                 # V2.0 â€” modern Python packaging
```

---

## ğŸš€ Quick Start

### 1. Clone & Install

```bash
git clone https://github.com/tamilarasu/ai-youtube-automation.git
cd ai-youtube-automation

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Install
pip install -e ".[dev]"
```

### 2. Configure

```bash
cp .env.example .env
# Edit .env with your API keys (see docs/SETUP.md)
```

### 3. Validate

```bash
ai-shorts setup
```

### 4. Run

```bash
ai-shorts run                              # Full pipeline
ai-shorts run --mode test                   # Test mode (story â†’ voice â†’ avatar only)
ai-shorts run --video-mode slideshow        # Slideshow mode (image-based, no avatar)
ai-shorts run --schedule "2026-03-01T10:00:00+05:30"  # Scheduled publish
```

### 5. API Mode

```bash
ai-shorts serve --port 8000                 # Start FastAPI server
# POST http://localhost:8000/generate {"topic": "...", "language": "en"}
```

### 6. Batch Mode

```bash
ai-shorts batch --input topics.json         # Process topics from JSON file
```

---

## ğŸ§ª Testing

```bash
pytest tests/ -v            # Run 31 unit tests
pytest tests/ --cov         # Tests + coverage report
ruff check src/             # Lint
ruff format --check src/    # Format check
```

---

## ğŸŒ Supported Languages

| Language | Code | Voice | Subtitles | Story |
| -------- | ---- | ----- | --------- | ----- |
| Tamil    | `ta` | âœ…    | âœ…        | âœ…    |
| English  | `en` | âœ…    | âœ…        | âœ…    |
| Hindi    | `hi` | âœ…    | âœ…        | âœ…    |

---

## âœ¨ V2.0 Features

| #   | Feature                     | What it does                                                |
| --- | --------------------------- | ----------------------------------------------------------- |
| 1   | **Randomized story styles** | 8 styles Ã— 5 tones Ã— 8 characters = 320 unique combinations |
| 2   | **Background music**        | Auto-looped at 1% volume via CompositeAudioClip             |
| 3   | **Styled subtitles**        | MoviePy TextClip with stroke, word-wrapping                 |
| 4   | **Scheduled upload**        | YouTube `publishAt` with auto privacy management            |
| 5   | **Kokoro TTS**              | Local CPU-friendly TTS, 100-word chunking                   |
| 6   | **Stable Diffusion**        | Local GPU image gen (SD 2.1, no API keys needed)            |
| 7   | **Image prompt gen**        | LLM summarizes story â†’ image prompt                         |
| 8   | **FastAPI REST API**        | Remote pipeline triggering via HTTP                         |
| 9   | **Batch processing**        | JSON file â†’ sequential pipeline runs                        |
| 10  | **Scene segments**          | Per-segment image generation domain model                   |
| 11  | **Slideshow mode**          | Image-based video without avatar                            |
| 12  | **Resumable upload**        | Chunked YouTube upload with progress %                      |

---

## ğŸ›¡ï¸ Resilience Features

- **Retry with Exponential Backoff** â€” All external API calls (3 attempts, 2-60s delay)
- **GPU Memory Management** â€” Automatic VRAM cleanup between pipeline stages
- **Whisper Model Fallback** â€” `large-v3` â†’ `medium` â†’ `base` on GPU OOM
- **SadTalker Fallback** â€” Ken Burns zoom effect if GPU inference fails
- **Graceful Degradation** â€” Subtitles, notifications, and Drive save are non-fatal
- **Typed Exceptions** â€” Each pipeline stage has its own error type (9 total)
- **Config-Driven Swapping** â€” Switch adapters via `.env` without code changes

---

## ğŸ“œ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

<div align="center">

**Built with Clean Architecture principles** â¤ï¸

_Demonstrating production-grade Python engineering: SOLID, DDD, Hexagonal Architecture, and System Design_

</div>
