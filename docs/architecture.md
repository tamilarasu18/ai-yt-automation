# ğŸ—ï¸ Architecture

## Design Philosophy

This project follows **Clean Architecture** (Robert C. Martin) with **Hexagonal Architecture** (Ports & Adapters) to achieve:

- **Independence from frameworks** â€” Business logic has zero external dependencies
- **Testability** â€” Every layer can be tested in isolation with mocked dependencies
- **Independence from UI** â€” The core pipeline can be driven by CLI, API, or Colab
- **Independence from external agencies** â€” Swapping Ollama for GPT-4, or SadTalker for Wav2Lip, requires changing only one adapter

---

## Layer Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Presentation Layer                     â”‚
â”‚  CLI (argparse + Rich)    â”‚    Google Colab Cell          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Application Layer                     â”‚
â”‚  PipelineOrchestrator  â”‚  Use Cases (single operations)  â”‚
â”‚  DTOs                  â”‚  Pipeline Modes (full / test)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      Domain Layer                        â”‚
â”‚  Entities (Topic, Story, Voice, Video)                   â”‚
â”‚  Value Objects (Language, Status, Privacy)                â”‚
â”‚  Ports/Interfaces (ABC-based contracts)                  â”‚
â”‚  Domain Exceptions (typed error hierarchy)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Infrastructure Layer                    â”‚
â”‚  Google Sheets (TopicRepository)                         â”‚
â”‚  Ollama (LLMService, StoryGenerator, MetadataGenerator)  â”‚
â”‚  Edge TTS (VoiceGenerator)                               â”‚
â”‚  SadTalker (AvatarAnimator)                              â”‚
â”‚  Whisper (SubtitleGenerator)                             â”‚
â”‚  SDXL (BackgroundGenerator)                              â”‚
â”‚  MoviePy (VideoComposer)                                 â”‚
â”‚  YouTube (VideoUploader)                                 â”‚
â”‚  Google Drive (StorageService)                           â”‚
â”‚  Telegram (NotificationService)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Cross-Cutting                        â”‚
â”‚  Pydantic Settings  â”‚  Structured Logging  â”‚  Retry      â”‚
â”‚  GPU Memory Manager â”‚  DI Container  â”‚  Pipeline Timer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Architecture Decisions

### ADR-1: Hexagonal Architecture (Ports & Adapters)

**Context:** The pipeline integrates 10+ external services (Ollama, SadTalker, YouTube API, etc.). Tightly coupling business logic to these services would make testing difficult and vendor lock-in inevitable.

**Decision:** Define abstract interfaces (Ports) in the domain layer. Implement concrete adapters in the infrastructure layer. Wire them together via a DI Container.

**Consequence:** Any external service can be replaced by implementing a new adapter. Unit tests use mock implementations of ports.

### ADR-2: GPU Memory Lifecycle Management

**Context:** Colab T4 GPUs have only 15GB VRAM. Running Ollama (LLM), SadTalker, Whisper, and SDXL concurrently causes OOM crashes.

**Decision:** Each GPU-intensive step runs inside a `gpu_context()` manager that automatically frees VRAM afterwards. The pipeline unloads models between stages.

**Consequence:** Predictable GPU memory usage. Pipeline stages can run sequentially on constrained hardware.

### ADR-3: Pydantic Settings for Configuration

**Context:** Configuration was scattered across a JSON file with hardcoded paths and no validation.

**Decision:** Use `pydantic-settings` with nested config groups, type validation, and `.env` file support.

**Consequence:** Configuration errors are caught at startup. All settings are type-safe and documented.

### ADR-4: Use Case Pattern

**Context:** The original `main.py` had all logic in one `run_pipeline()` function.

**Decision:** Split into individual Use Cases, each handling one operation with clear input/output contracts.

**Consequence:** Each operation is independently testable, reusable, and can be orchestrated in different pipeline modes.

---

## Data Flow

```
Google Sheets â”€â”€â–º TopicRepository.get_next_pending()
                         â”‚
                         â–¼
                  StoryGenerator.generate()
                         â”‚
                         â–¼
                  VoiceGenerator.synthesize()
                         â”‚
                         â”œâ”€â”€â–º AvatarAnimator.animate()
                         â”œâ”€â”€â–º SubtitleGenerator.transcribe()
                         â””â”€â”€â–º BackgroundGenerator.generate()
                                      â”‚
                                      â–¼
                              VideoComposer.compose()
                                      â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”
                              â–¼       â–¼       â–¼
                         YouTube   Drive  Telegram
```

## Dependency Injection

The `Container` class in `core/container.py` lazily resolves all ports to their concrete adapters. Each adapter is created once and cached:

```python
settings = Settings()           # Load from .env
container = Container(settings)  # Wire dependencies
orchestrator = PipelineOrchestrator(container)
result = orchestrator.run(mode="full")
```
